These subtitles have been generated automatically
Hey, welcome back.
So today I want to talk about a
particular challenge that's come up and become a big thing, especially in terms of online communities and democracy.
And we've talked about it a little bit
before, but I want to really focus on it today, namely polarization.
And, or the more extreme cases such as
radicalization.
Of course, this is not a new problem.
There's some some of the readings, at least the optional readings that provided for this week, take kind of a sociological perspective it's a very old problem sociologically.
But, you know, it, it really comes into
play in a big way in some of the in our online experience.
So, first of all, what is polarization in
general.
You can you can you define anyone define
it concisely.
Right. Yeah.
Whoops.
Yeah, so strong entrenched opinions.
Far from others, but who others from what
different, yeah, different the other side or different communities right so this. Yeah, so, so, you know this very important others.
So, so, so, so opposing or just, let's
say, ideologically different, right.
And this gets gets into into a very
important aspect that's it's it's often closely associated with, let's say, identity politics right.
Or, you know, group identity group identification.
Are you one of us, or are you
one of them, or are you one of them, or are you one of them, are you an insider or an outsider. Right.
And sometimes it really matters who them is
sometimes it doesn't matter that much which particular them you're talking about it's just that it says them that's not us right, depending on the situation.
So, yeah, so in in polarized cultures we
get these kinds of yeah strong entrenched opinions.
What, what else, what else often characterizes polarized
situations, either in terms of effects or possibly causes.
Right.
Great. So, here. Yeah, so the crux of
this is scapegoating, right.
Maybe this is a particular us term.
Or so, assigning trying to assign blame to
whatever might be ailing you, right, whether. Yeah, whether, you know, things are not going well economically which is often the, you know, very often the case or there's, you know,
something going on. It's easy and common for
people wanting power to, you know, try to create scapegoats say it's these people's fault it's those immigrants fall right. Yeah.
Very, very commonly.
And let's see what I was going to
add to something to that but just just lost it.
Yeah, hopefully it'll come back.
Oh yeah, actually for the previous term one
I meant to add a term that's often used for this is tribalism.
So, are they your tribe or not. Right.
Yeah, yeah, right, right.
Yeah, so, and this is this is actually
kind of a more specific case. Let's see if I can separate this out adequately. I'm not sure if that'll work or not. Yeah, kind of worked.
So, I'm offering, let's say, easy answers.
Or magic bullet solutions, right.
Great.
I don't have to deal with that the
whole class period I hope.
So, you know, and this is this tends
to be.
Yeah, this happens over and over, especially in
times of tension crisis, you know, kind of something's really bad is happening. Life is difficult for whatever reason, you know, opportunistic leaders politicians would be leaders.
And to be very quick to to offer
easy answers of all kinds, you know, and pointing fingers, a sign you blame creating scapegoats, often the immigrants, you know, whatever, whatever kind or you know, whoever is available to point fingers at, you know, I tend to get the brunt of that,
unfortunately, because it an easy answer is must
be their fault we let's let's do something right.
And of course, that's not new at all.
But it's, it's a just a regular and a human tendency at the at the large scale.
But even in small groups, certain kind of
well known processes can can actually lead to increasing polarization, even in groups that started out not not very polarized.
Can you think of some of these processes.
Again, this is kind of some of this is kind of classic sociology. Yeah.
Yeah. The one the reason we all have
to do ethics, ethics reviews for for our usability studies. Yes.
Yeah.
So the process actually affected strongly affected the
participants themselves, even though like there's experiment was supposed to study the participants but it actually made them, you know, very, you know, noticeably different people and not necessarily in a good way.
Right. So yeah, yeah. So, yeah, yeah, the
general principle that the process can, you know, can very much affect the participants right.
Whatever the process is and that's just an
extreme example. And, you know, it's a very important and historical extreme example but it's kind of an extreme example right.
Unfortunately, that doesn't happen all the time. And
now we have processes that try to make sure that doesn't happen happen anymore.
But the process does.
Canon does affect the participants for better or
worse right.
So what, you know, kind of outside of
that kind of extreme example, what are some kind of ordinary process tendencies like just an ordinary group of ordinary normal nothing wrong with them people debating stuff discussing stuff in a group.
And that lead a less polarized group to
be able to become a more polarized group and I'm kind of apologize and I kind of don't because this is this comes from, you know, some of the other readings that weren't the assigned readings but
but there are, you know, well well known
ways that, you know, kind of ordinary groups that we're not polarized can become more polarized.
And maybe some of you have been in
a deliberative group or trying to decide stuff and have experienced this or not. Yeah.
Great. Good. Good. So that's a great example
you're you're skipping ahead to, you know, one of the, you know, next topics that I want to want to discuss which is mitigations.
There are very important prominent ways to to
mitigate these tendencies and reduce polarization when when it's known to exist. And one of them is just get, you know, getting diverse people together.
And, you know, reasonably like either socially or
or discuss in discussion right.
Right. Discussion deliberation even just socially right.
Bringing bringing the often opposed groups, given more
familiar personal familiarity with each other, you, you know, you thought these guys were the so terrible and evil because you totally didn't understand them and you just
you were just operating on hearsay and then
you suddenly, you know, kind of meet some reasonable examples of that other population and oh maybe they're not so bad and maybe I understand them a little and yeah that happens. Yeah, good.
So let's let's come back to that very
soon but yeah so and that's obviously one way the process can affect groups for better right so process effects for participants can for better or worse right.
We have examples on both ways. Yeah, so
to focus more on the on the for worse parts. Oh yeah, go ahead.
Yeah, yeah great great example so personal attacks
Oops
So certain kinds of
Argumentative strategies that tend to be not productive.
That's you know a prominent example of that like and
But that's
Kind of more more broadly than that often
often in groups, you know groups are often
naturally diverse and
In many groups well, so so
You know you're
There will be most members of the groups
probably aren't going to engage in these kinds of personal attacks or particular
behaviors, let's say aggressive behaviors
And
Often these come from you know the individuals
that do exhibit this tend to be you know a certain type often, you know
Plot potentially very competitive, right?
I need to win this argument, but I
need to show you that you're wrong, right and I'm right
Because that's you know, that's who I am
and that right or or it or because it's
it's the
It's the larger group the ideal the ideology
the religion the tribe that identify with I have to
Push this and show that everybody outside my
tribe, you know is wrong and bad and you know, I
So, you know, there's various things that can
motivate this right
But
But even in a way kind of
Before and underlying that
Any diverse group tends to have you you've
probably heard the term vocal minority, right?
And
Often the majority is much less vocal silent
majority
And these are terms that apply tend to
apply both to small groups and to large groups, right?
Even in a small group
There's the one or two
Highly opinionated people who always have to be
talking and always have to be having their way
I know I'm right. Yeah, but yeah interrupting
anybody else who who's trying to make another point or you know
kind of basically stealing the show whether they
need to or not, right and
And you know, maybe the others are sitting
there
Okay, when do we have to keep listening
to this turkey when can I go home? Yeah, is it
Are we done yet? Do I have to
say something? Maybe I should say something but I've got to talk to them, right?
And you know often
You know and even just in ordinary smaller
to medium-sized group discussions these can these can be very prominent effects
if
Something or someone isn't moderating them, right?
And this is this is what leads to
has led to practices like Robert root Roberts
rule rules of order for
civilized debate and things like that to try
to
mitigate some of these these natural tendencies and
make sure you know group members, you know
Have relatively equal equal time to speak regardless
of whether they're the vocal minority there or the silent majority, right?
They're not necessarily perfect, but you know these
been
issues and and practices kind of countermeasures for
for a long time and
Yeah, and so without adding you know with
without
Kind of recognizing and doing something about this
natural tendency of human groups
It's very very common for
There to be a vocal minority who will
you know if left unchecked right to kind of take over right and
engage in personal attacks aggressive behavior win at
any cost, right?
as a as opposed to trying to
You know kind of trying to understand other
people and you know
And so that that's one one way that
polarization can can increase right
Because well the vocal minority kind of carries
the day even though they're not representing the opinion of the major
majority, but
Nobody's hearing from the majority. Yeah
the perception or the importance of say random
variations
in the group, in the members culture perspective,
you know, it's kind of some things usually
wouldn't be important at all, but because one
of these
kind of minor random events happens,
suddenly it seems very important in the context
of that group and kind of steals the
show, yeah,
and can totally polarize the group, indeed, yeah.
Good, yeah, so these are examples where that
can cause,
they can cause groups to either polarize internally,
like kind of the group splits into like,
you know, okay, different camps that can't agree
with each other or don't like each other,
or sometimes they can,
so especially in the vocal minority case,
and if the silent minority members just don't
have
that strong of opinion on some of the
things being discussed,
they might just go, okay, sounds fine,
I don't see any immediate reason to disagree
with this vocal minority who seems to be
the expert
on this topic, because they can certainly say
a lot about it, right?
So yeah, sounds like they must be an
expert, yeah, okay,
I'll go along with them.
And sometimes the vocal minority does not get
a lot of pushback and the whole group
goes in that way,
and you know, and kind of the group
as a whole,
the others, you know, basically kind of become
more,
let's say, ideologically influenced in that direction,
like they never thought about it,
didn't have a position before, but well,
I heard from this expert, you know,
a very vocal expert who knew a lot
about this,
and yeah, I guess I see his sort
of her point,
and guess I'm in that group now too,
right?
And you know, so this can lead, you
know,
kind of the whole group,
including the previously, you know,
kind of non-committed members into a direction
that's polarized with respect to the larger population,
the larger society, right?
There's another related tendency
that can again happen totally accidentally,
even really without, you know,
even in those groups that don't really
have a dominant vocal minority, right?
You know, sometimes that happens too,
like the group really gets along,
everybody, you know, is kind of respecting each
other
in the discussion, and you know,
nobody is dominating or interrupting everybody else
or engaging in personal attacks,
but still the group can kind of veer
off
in some direction that kind of polarizes the
whole group
from the perspective of the larger world.
There's a particularly well-known term
for how this can happen, anybody,
anybody recognize this tendency?
And in fact, it can happen when like
the discussion
is going great, you know,
what should we do about this important problem?
You know, how do we solve it, right?
And somebody, you know, has an idea
and the rest of the group kind of
continues
to develop the idea, yeah, we should totally
do this.
And you know, everybody is absolutely in agreement,
this is the solution.
And then only much later, it turns out
that that was a terrible idea,
or it's completely at odds with, you know,
kind of what the rest of the public
or what, you know,
what's compatible with reality
or with larger society or something, right?
Is this familiar at all?
Yeah?
Yeah, maybe like a guru.
Sorry?
Like a guru, you know?
Yeah, a guru, I'm sorry, yeah, yeah.
So that can, yeah, a guru can totally
lead a group
or like a, you know, cult leader or,
yeah.
So that can totally happen,
but I would still kind of put that
in the vocal minority category, right?
Because like the guru totally knows
and thinks or knows he knows and, you
know, but yeah.
But I don't know.
That follow people who just end up by
their own people.
Yeah, exactly.
Good, yeah, you're right on.
And at least in my experience,
the classic term for this is literally just
called groupthink.
Anybody heard this term?
Maybe it's a particularly US term again,
but I don't know if it's something,
but there's a, yeah, there was a term
for this.
It's called groupthink.
Happens all the time.
Totally accidentally, nobody's fault.
Nobody's trying to make it happen.
But, you know, the discussion just randomly goes
in a certain direction and this happens very
innocently,
like in totally random things like software design,
game design, you know, where like, you know,
the group just is deciding on a course
of action
and, you know, they come up with something
they collectively think is a great idea
and they develop it and develop it and
develop it,
you know, in a certain direction.
And then like, you know, in the case
of a game
or other software, it meets real players.
It meets reality in some way.
And then only then, after hours, days, months
of serious development, like by this group,
it meets reality and suddenly like, it completely
blows up.
Like, you know, and everything is totally wrong,
right?
You know, because the whole group was not
considering
kind of, you know, was thinking here, you
know,
about this stuff and totally completely neglecting
this little fact of reality over here.
I should have a good example offhand.
I know, you know, there are some really,
really good classic examples of this happening.
And I think about, you know, one right
now,
I should have one more at hand in
the future,
but maybe you can think of cases of
this happening.
But yeah, you know, it happens, you know,
alarmingly often.
Yeah, and why is that?
Well, it's because actually the group, you know,
was in some sense too productive,
but working in their own bubble
without further external input, you know,
or without testing what they were doing
against the rest of the world, the surrounding
environment,
or, you know, outside people who might bring
more diversity
into the picture.
Like, you know, just the one person, you
know,
kind of they could have avoided this disaster
if at one point early on they had
gotten
some external review and someone would say,
hey, didn't you forget this?
Or, you know, what if somebody does that?
Or if somebody is like this, or, you
know,
and in retrospect, it turns out to be
a completely obvious,
you know, why didn't I think of that?
We wasted so much time, you know,
this total direction is never gonna work.
And, you know, and this afflicts software development
and hardware, all kinds of engineering
because it's, you know, just accidentally happens
very naturally, but it can also happen
in political context too, right?
So a group is deliberating on, you know,
some solution to a social political problem
and, you know, things they've got a great
idea,
the great solution, but it's actually a terrible
solution.
It completely leaves out, you know,
these particular subsets of the population,
possibly big, possibly very important,
and it totally blows up when it meets
reality, right?
Yeah.
Let's see what else today.
Yeah, any other thoughts or examples you can
think of
or like behaviors,
or effects leading toward polarization?
Yeah.
Mm-hmm.
Yeah.
Right.
Good. Mm-hmm. So these are great examples like
how how even totally unintentional
kind of labeling can
Can turn into an identity politics thing just
absolutely, you know accidentally. I'm sure nobody at Apple, you know
was
You know consciously trying to create
You know that a whole identity politics problem
around the color of their messages like sound like a good feature, right?
But oh it did
Yeah, yeah great great example
So SMS versus I message good example
Forgot second S in there, but anyway
Okay, yeah, great. So so these are some
some really good examples of
How poor polarization plan on
Form and an increase, you know either intentionally
or unintentionally. Yeah, so let's let's look at you know some
mitigations and you know you brought up a
you know one of
One of the good examples, huh?
Huh
Actually well before we get to that I'm
gonna do things slightly out of order
So we didn't really let's let's focus on
you know one of the one of the readings was about
About the question of how
How algorithms like the YouTube's recommendation algorithm can
potentially
lead towards increased radicalization, right? So let's let's
talk about a little briefly about
specifically about algorithms and
Polarization right how can algorithms
In particular
Need to polarization and there are multiple again
multiple potential ways. Yeah
Great
Yep
Mm-hmm
Yep, exactly. So the algorithm kind of doesn't
care in principle what kind of content it's pushing
But it wants more eyeballs on the screen
for more time, right and it so happens that
Shocking or emotional
Emotive
Content
Tens to just naturally for totally ordinary human
region reasons tends to lead to more engagement, right?
You see something a shocking video you got
to click more and you know, right? Yeah
Yeah.
Exactly.
Yeah, yeah.
Great, great example. Yeah, many of these algorithms
are trying to, you know, seek the like, you know, kind of the next thing to suggest that's most likely to, you know, to succeed in, you know,
to succeed in its objective of keeping your
eyeballs glued to the monitor. And, you know, that that choice might be completely disproportionate to, you know, to the larger, you know, kind of proportion percentage, you know, so yeah, and you wanted to add something to.
So you're talking about like when the advertising
industry is trying to
present ads that appeal to the largest population,
like the least common denominator,
or try not to shop when you want
to appeal to the problems.
Yeah. So do you see that? So is
that a do you see a way that can accidentally increase
polarization? Or are you talking about that in
terms of a mitigation?
Yeah. Yeah. So certainly another way to mitigate
polarization is to have a deliberate
algorithmic design
to let's say,
say toward proportionality, right?
Now this in some cases may succeed, in
other cases may fail, but sometimes,
people actually deliberately do try to preserve some
kind of notion of proportionality, right?
Kind of appeal to the broadest population, avoid
stepping on toes. And yeah, I think you're right.
The advertising industry often fairly consciously does that,
sometimes succeeds, sometimes fails.
Yeah. And that can be, you know, sometimes
successful mitigation strategy too.
Yeah. Good.
So yeah. And again, we'll come back to
mitigations more. Yeah. Go ahead.
Opinions is one of this, graded...
Yeah.
Yeah. So a risk here, yeah. So even
when you're trying to be proportionate,
So one of the risks is basically, yeah,
as though only popular opinions or perspectives.
of representative, you know, kind of respond to
a representative sample to the culture of the culture,
but the representative sample was not big enough.
And it did not randomly sample any single example
of this, that, and the other relatively, you
know, rare, you know, smaller, smaller group, right?
Just because, you know, well, that's what statistic
does. You know, samples, it represents,
it reliably represents the big populations, the broad,
you know, popular opinions, and it does not,
you know, cannot guarantee to represent at all
the rarer cases, right? So, yeah, that's just,
what's the, what's the standard technical term for
the, oh yeah, that's the rare event problem, right?
Standard term in statistics, right? If you've got
a rare event, you know, a statistical sample is
not at all guaranteed to find that, right?
And that can, that can certainly be a
cause real problems. Yeah, but even when, when
that doesn't happen, as yet, yeah, coming, coming back to,
you know, ways that algorithms can, can increase,
can create and increase polarization.
Let's see, I had
a question.
Ah, yeah, yeah. So, beside, yeah, so besides
these kinds of, you know, kind of a motive or
amplification-based things, ah, yes, there's also, on the
posting side, who's producing the content
that's being, being, you know, kind of being
presented or chosen from. Well, there's,
there's a standard, you know, there's some lessons
that people learn quickly when,
you know, if you want to become an
influencer on social media, if you want a lot of, a lot of
followers, a lot of people to follow you,
will, you know, there's certain, certain things, you know,
you have to do, you have to post
often, right? First of all, you have to make yourself a vocal
minority by posting often, people have to hear
from you often, you know, regularly.
And consistently,
in terms of topic, what, you know, topic
style, what you post about, you have to create
a particular online identity and maintain that so
that, you know, people who like,
like what you said in the past will
continue to like what you say in, in the future, because it's
still the same kind of thing, right? Yeah.
Yeah, so say broad appeal and accessibility, like
the language example.
Yeah.
Yeah, so these kinds of factors can increase,
right?
You know, greatly increase the chance that somebody's
content, you know, somebody gets
popular in their content, gets popular and seen
a lot, right?
In a way, this is just another example
of the vocal minority effect, right?
Only there is a strong incentive because, you
know, you get rewards, you get advertising
rewards and other kinds of rewards for being
an influencer, getting the status, right?
And so there's a built-in incentive to become
that kind of vocal minority, right?
And so, you know, we're again back to
the principle that the process, the whole social
networking process affects the participants.
Again, it creates incentives for some subset of
the participants to become these kind of
devote their lives to becoming an influencer and
pushing stuff online.
And does it surprise us at all?
Why should it surprise us when the content,
the types of content that many of these push
tend to lead towards, you know, polarization in
one way or another because, well, that's
what captures and maintains people's attention, right?
Yeah.
Okay, good.
So, yeah, good time for the break.
So let's take the break, come back at
4.15 and talk more about mitigations.
Good.
So let's talk more about what we can
do about some of these polarization kind of things.
And as I hope has become obviously one
of the themes in this course, even though I want
us to recognize all the important risks like
these, I also am not a fatalist.
I don't think we should accept the position
that, you know, there's nothing we can do
about it.
It just happens.
It's not our problem.
Somebody else's problem, nothing we can do about
it, right?
Unfortunately, I see that attitude all too common
among, you know, flavors of that attitude,
all too common, especially among geeks, right?
You know, it's either not our problem or
just nothing we can do about it, right?
Because there are things we can do about
it.
It's, these are very much depend on choices
we can make in designing systems, processes
and whatnot.
So, yeah, you've already suggested a couple, a
couple good mechanisms that can, you know,
to some degree within limitations, of course, help
reduce, reduce these kinds of effects.
Okay?
Do we unpack these more or think of
others?
Yeah?
Yeah, so just better, better education, better, better
information, right?
Where the facts, often like just, you know,
kind of knowing the facts a little bit better,
having access to that can help, right?
Not guaranteed to help, of course, but yeah,
so who, I don't know who is first.
understanding why certain people or groups think the
way they do, what actually brings
them to this position, often tends to be
the key to kind of, if there's a way to kind of
break through and kind of bring a little
bit more kind of consensus or at least mutual
understanding, find a way to communicate, it often
has to start with that like where
understanding well where they're actually coming from, what
you know kind of getting
past the you know what is the entrenched
position to where did that position come from and
yeah and that's again you know coming back
to this you know kind of the very top point
that one of the ways that just kind
of getting diverse people talking you know kind of under
the right constraints right you know kind of
these these you know kind of the rules and
the constraints matter a lot you know and
can make the process work or not but this is another
way that you know getting diverse people can
can help because oops didn't quite work try that
again that worked better because because representatives of
positions or ideologies or
groups subgroups are better right can be better
at relating you know explaining the positions
of other members right diverse in diverse groups
you know kind of you're more likely to have someone
who can act as a kind of a
natural bridge like someone who you know maybe does not strongly hold
that position but maybe comes from that community
or not far from and say oh wait I understand where
they're coming from I can tell you why
they have this entrenched position and this is you know if
you want success this is not how you
need to talk to them you need to understand this you need to
right no and you know that that kind
of critical just kind of information about what you know kind
of different groups you know how different people
different groups think you know I mean it's there's
no certainty but it's at least more likely
to be represented and available in a more diverse group
and conversely coming back to this problem I
mentioned a group think you know very often you
know this is one of the most you
know this is the one of one of the worst problems of self-selecting
groups like you know kind of groups like
most software development teams I'm here we're here
because we want to build games and we're
all like each other because we all like games or you know
we all like this particular kind of game
even because you know because it's fun and we do it and
or you know right self-selecting groups very easily
kind of completely you know kind of focus on
what is in their experience and totally are
completely unaware of what people with a very
coming from a very different background with a
very different experience might be thinking or
how they might react to what you what
you built right so sorry you've been you've been waiting to
So you bring up, which especially applies to
climate change because there are,
kind of, it's not at all an accident
that there's this large body of misinformation about it, right?
Because there are very entrenched economically and politically
powerful groups that want to pretend,
you know, kind of want things to go
on as if climate change wasn't a thing, right?
Because, well, it would be uncomfortable and economically
painful to their businesses to do otherwise, right?
And so they have a, you know, kind
of very strong incentives to, you know,
invest money in, you know, in making polarization
happen in their way, right?
So we've, you know, we've kind of been
talking about the many ways polarization can happen accidentally,
but yeah, it can only happen deliberately too,
and, you know, you're right.
So when there's, you know, powerful, well-funded bodies
that are trying to make it happen.
On the other hand, yeah, and actually, you
know, we're going to talk about that,
but some, you know, potential mitigations to that
next week, in fact,
there are mitigations that are, I think, applicable
here too now, though.
So, which brings me, yeah, to a, you
know, again, not perfect.
So you're right, like, you know, kind of,
you know, in a, say, you randomly sample a group of people,
you know, some of them might randomly be
climate deniers because they were, you know,
kind of immersed in news from this, you
know, kind of climate denialist position,
and, you know, they're just coming, you know,
not because, you know, the random sample was bad in some sense.
There really are a lot of climate deniers
just because they've been, you know, kind of enmasked, influenced,
you know, by this client denialism perspective. That's
one way this might happen, right?
But, you know, another way as well that
it could happen is, well, the group is being formed,
and, but then the, you know, climate, climate
deniers find out, okay, who's in the group
and who can we actually actively influence, right,
corrupt, you know, in some sense,
to spread our position instead of their own,
right?
And so that's another, you know, kind of
way this can potentially happen depending on, you know,
what kind of process we're talking about, right?
Both are possible. They might be different, you
know, with different levels of likeliness in different situations, right?
Yeah, and, you know, we'll talk about that
partly next week, and also I want to come back to that in a minute with another mitigation too,
Yeah, yeah, you're right.
And yeah, you brought up several very important
kind
of structural tendencies that affects, you know,
kind of the strongly affect, you know,
whether this kind of polarization happens or not.
And like the, you know, especially this, you
know,
kind of the fact that like the,
the kind of the Wall Street bankers
tend not to get punished for their misbehavior,
you know, especially the fact, the combination of
the fact
that, you know, kind of the, those that
are most inclined
to say push climate denialism for economic reasons
are also for, you know, the reasons you
bring up
very likely, very unlikely to get punished
for outright really blatant, you know,
fraudulent behavior just because yeah, they're, you know,
rich and kind of tend to be protected
from,
from punishment or have very light punishments
if they get caught, you know, at all,
right?
This creates a very perverse incentive structure,
you know, against, you know, that,
you know, naturally makes this, you know,
very difficult problem to deal with in many
contexts,
including some of the most important
where all the money is.
Yeah, so certainly, yeah, that's not an easy
problem.
But yeah, again, as you point out as
well, you know,
there are obviously, you know, it's not something
that's, you know, just kind of necessarily has
to be that way.
And, you know, there are, you know,
very clear structural issues we can point to.
And, you know, in other parts of the
world,
like you mentioned Finland, you know,
where they, you know, done things a little
bit
structurally differently.
And, you know, in such a way that,
you know,
the kind of education you get does not
depend so much
on whether you live in a rich neighborhood
or a poor neighborhood.
And, you know, that, yeah, that makes a
difference.
I think,
yeah, so another,
whoops, okay.
Another mitigation that I wanted to point out
that's totally not perfect, but does help.
And even including in these cases of, say,
climate denialism, right, you know,
where they're really strong incentives,
you know, some parties are really pushing
misinformation actively.
One thing, you know, not perfectly,
but can help a lot is just information
labeling,
provenance.
Where did some information come from?
Who is it from?
What group, what company, right?
Now, you know, this is not always easy
to do, of course.
There's plenty of technical and social challenges
in figuring out, well, how to do a
good job
of labeling information.
And, you know, who does the labeling?
And, you know, there's a bunch of second-order
problems
that I, you know, want to acknowledge there.
But, you know, numerous studies have,
you know, have looked at this and found
that, you know,
when ordinary people are exposed to
either good information or misinformation,
including deliberate, you know, kind of misinformation,
like climate denial type information.
They tend to be more skeptical of it
if they are, or, you know, more able
to process it,
you know, so rational skeptical way
if they see something about where it's coming
from,
like who's pushing it?
Where who's, you know, what group it comes
from?
What, you know, what group does it come
from?
And what else, what type of stuff do
they post?
Rather than just it's kind of a random
tweet
that magically appeared on my feed with no
context
or, you know, anything behind it, right?
And so, yeah, just that aspect
can have a significant impact, right?
Of course, you know, people can still get
unduly influenced
or, you know, can believe what they want.
But, you know, they do tend to be
more skeptical, right?
And more rational, you know, when they're,
when they kind of see where things come
from,
when they get meta information about the information,
right?
Ah, yeah, another good point that I think
one of your comments actually touched on,
that I wanted to bring in actually coming
back
onto the negative side, actually.
And this especially applies, you know,
again in the, you know, climate denialism
and in some other cases, the tendency to,
you know, what's the right term for this?
False balance.
And traditional, many traditional journalists
are especially guilty of this,
especially on certain topics such as, you know,
climate change, right?
There's, you know, the vast majority of the
world scientists,
you know, this is a completely,
this was a completely settled thing decades ago.
And there's no real debate about whether, you
know,
climate change is real.
But there are these couple cranks here, there
and there
that keep getting trotted out
to represent the climate denialist perspective.
And these are respected professors
of this, that and the other, right?
They're always, you know, kind of out, you
know,
representing the climate denialist perspective,
because well, you know, maybe they either believe,
truly believe that or they've been paid off
away.
Who knows what, but there are a few
that can be found
to and kind of the traditional journalist kind
of mode
of operation is, well, if there are two
sides,
equal time to both sides, right?
So trying to,
trying to take a, you know,
an issue in which, you know, kind of
the evidence,
the experts, the whatever are not at all
imbalanced
and pretend that they are imbalanced, right?
Can actually, you know, work against,
and create more polarization and naturally create,
you know, help the client climate deniers
by creating this kind of false sense
of the false view perspective of legitimacy
when there is really no scientific legitimacy, right?
And so that's where I think, you know,
we came, yeah, so the discussion brought us
to this point before, you know,
if we're designing algorithms or social processes
or something and we're trying to capture some
form
of proportionality, we need to think carefully what
that,
what is, you know, what is the underlying
sample population
we're sampling and what kind of proportionality
are we creating and, you know, kind of
avoiding
some kind of naive false balance type, type,
type perspective.
Oh, there's two sides, let's treat them equally
or, you know,
so of course it's easiest to just, you
know,
take two sides and treat them equally, but,
you know,
that's kind of the lazy approach
and we see the harm that can come
of that.
And so that's the question.
But yeah, you know, especially in,
and here's where, you know,
that in our, you know, kind of modern
technology,
we have the opportunity to do so much
better, right?
Because in the like, you know, algorithmic content
selection systems, we tend to have not just
two,
but many perspectives that are represented in the
data
and the discussions out there in the, you
know,
social media and whatever, you know,
there's almost never just two,
there's a big distribution, right?
And the systems we build and can easily
build
and maintain are big enough, are scalable enough
to deal with more than just two perspectives.
There's no need anymore, you know,
even if there was ever kind of, you
know,
maybe this journalistic tradition came
from a practical need, you know, way back
when,
to kind of simplify all problems into, you
know,
kind of pretending there are only two sides,
when often there are three, four, five different
perspectives
that are actually of interest, you know,
just focus on the top two, you know,
and pretend they're equal, even if they're not,
right?
But, you know, we don't need to,
why do we still need to do that,
right?
And in the, you know, in our approaches
to either
designing algorithms or kind of managing discussions
at large scales, we have lots of options
to, you know,
processes with which we can, you know,
manage larger number of different positions
and, but keep them in proportion.
And this is, you know, again, coming back
to, you know,
even though I've talked about it many times
already,
the ideas around like liquid democracy, like, you
know,
kind of a nice feature of that is
it kind of tries
to kind of acknowledge that, well, there can
be many positions,
some of them have more support, some of
them have less,
let's expose that, but allow them to remain,
allow all of them to be expressed,
but in a proportional sense, right?
So, you know, actually doing that perfectly is
hard.
There's still many problems, but, you know,
we seem to have handles on some of
the,
some ways to, you know, ways forward in
this, right?
Um, yeah, yeah.
Are there other mitigations you can think of?
Actually, another that I will toss out is
just
Actually, another that I will toss out is
just finding ways to increase the breadth and diversity
of people's information diet, as we say.
How do you get the information you munch
on on a regular basis when you're doom scrolling on your phone
or whatever you do, however you get your
information?
Well, that's your information diet, right?
And people study this.
There's a lot of good interesting papers about
people's information diet and how they get to be this way or that way.
Right?
Right.
And, you know, one of the things that,
you know, we haven't talked about, we've talked about in earlier sessions, but we didn't come up that much in this one is the whole social media idea of, you know, kind of orienting your feed towards things that your friends, you know, are saying, what's popular among your friends, your social circle and really focusing on that.
Well, you know, that was, you know, it
seemed like a good idea from a, well, you know, kind of what from, from a, you know, engagement perspective, yeah, what you like is probably similar to what your friends like so the, you know, algorithms are likely to keep you and
engage better, make you more interested, whatever, if
you're seeing, you know, mostly what your friends like, you know, but then, you know, in retrospect, what that, that was another major, you know, kind of potential polarizing factor because, well, you know, most of the time you're just seeing what your
own community, your own tribe already believes is
the reality and, and, you know, and even though it's, you're completely, you're kind of completely living in a bubble, you're living in a big ish bubble, you know, that includes all your friends, but you're not even aware of it because well it's completely different from what the, the another large population including like, you know, in the US right
there's these kind of two big in, you
know, the big blue info information bubble and the big red information bubble right and
and many of the members, you know, kind
of most most if not all of their social contacts are either all blue or all red, and you're never going to see the other one and like how can people believe that other position when yeah you never you're never actually exposed to it because
you know, you live in you live live
in one, one bubble or the other right, but we can, you know, we can make different choices for, for our, for our feeds and one of the, you know, one of the, you know, sometimes tough choices, because, you know, deciding not to focus a feed on things your,
your friends or your social community, you know,
your social media tends to like and approve of, you know, might, might seem to make your, your feed your information diet less palatable because well it comes comes with all these kind of less comfortable things from outside your bubble that you don't
necessarily agree with or like so much right.
And, and so kind of the, the proposition
that like, you know, let's let's reprogram your feed to make it less attractive less likable less fun.
And it's kind of not a, you know,
kind of a slightly tough proposition, right, for you, you know, go to Facebook and Google say hey, you know, I have a great idea to make your feeds less likable to your users, you know, Mike Zuckerberg can go yeah, right.
So, but you know, an increasing number of
people, you know, I think, recognize that, well, maybe somehow we need to figure out a way to way to do this.
You know, because, you know, numerous studies show
that actually kind of a broader, more diverse information diet, you know, can help with this but yeah, how do you do it. Yeah, you wanted to.
But they're trying to be consistent with the
ideological bubble they selected in the particular, you know, kind of niche they've dug for themselves, because that helps them get get followers and right views and stuff like that.
Yeah, so that's.
Yeah.
Yeah.
Mm hmm.
Yep. Absolutely. Yeah.
So, yeah, so these are great examples but
yeah so so I think again, you know, it's clear there's, you know, lots of ways that, you know, polarization can happen either intentionally or or or unintentionally.
There's a lot of also ways, a lot
of ways we can, you know, try to, you know, work against that can be conscious and starting with being conscious of that tendency and, you know, designing systems, you know, better right.
Sometimes it's, you know, sometimes it's easier sometimes
more difficult when we're working against very vested vested interests but, you know, there's there's things we can do right and there's no, you know,
and I think, you know, especially when we're
when we're dealing with systems talking about building systems and maintaining systems that are processing the information diet that everybody is going to live on.
I'm looking at you AI, which I still
need to, I meant to talk about more but probably not going to have enough time but you know we need to be a lot more conscious of, you know, how the particular systems how the particular
decisions we make algorithmic decisions incentive decisions you
know we make on those systems is actually going to affect, you know, people's information diet and the way they might, they might think is it going to make our systems going to
better people or worse people right because they
nothing is neutral they're they're not going to be neutral one way or another.
Yeah.
Yeah, any other thoughts on this topic.
No, not good. Thanks for the great discussion
so next next week we'll talk about electronic voting and interesting topics around that, including coming coming back to this question of like deliberate misinformation and voter influence and anything we can do about that
So, so yeah have a great week and
looking forward to seeing you again next week for the, for the last, last week before break.
